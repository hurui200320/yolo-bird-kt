package info.skyblond.yolo.bird

import ai.onnxruntime.OrtEnvironment
import ai.onnxruntime.OrtSession.SessionOptions
import com.github.ajalt.clikt.core.CliktCommand
import com.github.ajalt.clikt.core.terminal
import com.github.ajalt.clikt.parameters.options.*
import com.github.ajalt.clikt.parameters.types.double
import com.github.ajalt.clikt.parameters.types.file
import com.github.ajalt.clikt.parameters.types.int
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.launch
import kotlinx.coroutines.runBlocking
import java.io.File
import java.time.Duration
import javax.imageio.ImageIO
import kotlin.math.ceil
import kotlin.time.measureTime

fun main(args: Array<String>) = MainCommand().main(args)

class MainCommand : CliktCommand(
    name = "yolo-bird",
    help = """
        A tool for detecting bird from camera recordings.
        
        This tool requires a working directory with the following structure:
        + sub folder `raw` to store recordings
          + The content under this folder should be named like `name_YYYY-MM-DD_HH-mm.format`.
            For example: `rec_2024-05-25_09-25.mp4`.
          + sub folder `processed` to store chunked recordings
            + The processed footage will be organized by date, for example:
              The clip `rec_2024-05-25_09-25.mp4` will be put under `processed/rec_2024-05-25`
        + sub folder `clip` to store chunked clips
          + The clips are generated by ffmpeg with segment muxer.
          + The result will be `name_YYYY-MM-DD_HH-mm_id.format`.
            The `id` start with 0. For example: `rec_2024-05-25_09-25_16.mp4`
        + sub folder `interest` to store clips
          + After processing, the interesting clips will be moved from `clip` to this folder.
          + sub folder `concat` to store the concat video file
        + sub folder `evidence` to store 1 boxed frame to show the detected interest
          + When a clip was moved from `clip` to `interest`, the program will
            generate a png image showing which target has been detected.
            This is useful to see if the model detects the wrong thing.
    """.trimIndent()
) {
    private val interests by option("-i", "--interest")
        .convert { s -> s.split(":").let { it[0] to it[1].toFloat() } }
        .multiple(listOf("bird" to 0.6f))
        .help {
            """
                Using `-i label:threshold` to set what you're looking for.
                The threshold must be ranged in `[0, 1]`.
                
                For example: `-i bird:0.6` will find all birds with confidence
                greater or equal than 0.6. 
                
                You can have multiple interests, and a clip is considered as
                interesting if any of the interest target is found.
            """.trimIndent()
        }
        .check { l -> l.all { it.second in 0f..1f } }

    private val nmsThreshold by option("-n", "--nms-threshold").double()
        .default(0.7)
        .help {
            "NMS Threshold, bigger value leaves more overlapping boxes, " +
                    "while smaller value leaves less overlapping boxes."
        }

    private val ffmpegPath by option("--ffmpeg")
        .default("ffmpeg")
        .help { "The path to ffmpeg executable, by default find from PATH" }

    private val format by option("-f", "--format")
        .default("mp4")
        .help { "The extension of the video, by default is mp4." }

    private val skipFrame by option("--skip-frame").int()
        .default(6)
        .help { "Grab 1 frame from every N frame" }
        .check { it > 0 }

    private val bufferedVideo by option("--buffered-video").int()
        .default(1)
        .help { "Buffer how many video files in RAM" }
        .check { it > 0 }

    private val yoloLabels by option("--label-file").file(
        mustExist = true, canBeFile = true, canBeDir = false, mustBeReadable = true
    ).help { "Override the default labels from coco dataset" }


    private val workingDir by option("-w", "--working-dir")
        .file(mustExist = true, canBeFile = false, canBeDir = true)
        .required()
        .help {
            "The working directory."
        }

    private val split by option("-s", "--split", metavar = "length")
        .convert { Duration.parse(it) }
        .help {
            """
            Split the raw footage into clips, and put into the `clip` sub folder.
            
            The duration is in `java.time.Duration` format, for example:
            + 1 minute is `PT1M`
            + 90s is `PT1M30S` or `PT90S`
        """.trimIndent()
        }

    private val process by option("-p", "--process")
        .file(
            mustExist = true, canBeFile = true, canBeDir = false, mustBeReadable = true
        )
        .help {
            "Process the clips in the `clip` sub folder, " +
                    "and put the interesting clip into `interest` sub folder, " +
                    "using the given yolov8 onnx model."
        }

    private val concat by option("-c", "--concat").flag()
        .help { "Concat the interest clips into one giant video by day" }

    override fun run() {
        val rawFolder = workingDir.subDir("raw")
        val processedRawFolder = rawFolder.subDir("processed")

        val clipFolder = workingDir.subDir("clip")

        val interestFolder = workingDir.subDir("interest")
        val concatInterestFolder = interestFolder.subDir("concat")

        val evidenceFolder = workingDir.subDir("evidence")

        split?.let { duration ->
            echoSuccess("Splitting footage...")
            splitVideos(
                inputFolder = rawFolder,
                outputFolder = clipFolder,
                processedFolder = processedRawFolder,
                extension = format,
                duration = duration,
                ffmpeg = ffmpegPath
            )
        }

        process?.let { model ->
            echoSuccess("Processing clips...")
            val inferenceParameter = InferenceParameter(
                nmsThreshold = nmsThreshold,
                interestMap = interests.associate { it }
            )
            doProcess(
                model = model,
                inferenceParameter = inferenceParameter,
                clipFolder = clipFolder,
                interestFolder = interestFolder,
                evidenceFolder = evidenceFolder
            )
        }

        if (concat) {
            echoSuccess("Concatenating interesting clips...")
            concatVideos(
                inputFolder = interestFolder,
                outputFolder = concatInterestFolder,
                extension = format,
                ffmpeg = ffmpegPath
            )
        }
    }

    private fun doProcess(
        model: File, inferenceParameter: InferenceParameter,
        clipFolder: File, interestFolder: File, evidenceFolder: File
    ): Unit = runBlocking(Dispatchers.Default) {
        echoSuccess("Preparing ONNX Runtime...")
        val labels = yoloLabels?.let { f -> f.readLines().filter { it.isNotBlank() } }
            ?: YOLOv8.cocoNames
        val env = OrtEnvironment.getEnvironment()

        echoSuccess("Loading ONNX model...")
        val yoloV8 = YOLOv8(env, labels, model) {
            addCUDA() // TODO: assuming we're using CUDA, since CPU is too slow
            setOptimizationLevel(SessionOptions.OptLevel.ALL_OPT)
            setExecutionMode(SessionOptions.ExecutionMode.PARALLEL)
        }
        echo(
            """
                Model input: 
                    width: ${yoloV8.inputWidth}
                    height: ${yoloV8.inputHeight}
                    channel: ${yoloV8.inputChannel}
                    batch size: ${yoloV8.batchSize}
                    output labels: ${yoloV8.outputLabelSize - 4}
            """.trimIndent()
        )

        echoSuccess("Prepare file channel...")
        val videoChannel = readVideoFiles(clipFolder, format, skipFrame, bufferedVideo)
        echoInfo("Format: $format, skip: $skipFrame, buffered video: $bufferedVideo")
        echoSuccess("Start processing...")
        // looping
        for ((file, video) in videoChannel) {
            echoInfo("Processing $file, total frame: ${video.size}")
            echoInfo("*".repeat(ceil(video.size / yoloV8.batchSizeInt.toDouble()).toInt()))

            val time = measureTime {
                val result = yoloV8.doInference(video, inferenceParameter) { l ->
                    if (l.flatten().any()) echo(terminal.theme.warning("+"), trailingNewline = false)
                    else echo(terminal.theme.info("-"), trailingNewline = false)
                }
                echo()

                val (interestFrame, interestDetections) = video.zip(result)
                    .filter { it.second.isNotEmpty() }
                    .maxByOrNull { (_, d) -> d.maxOf { it.confidence } }
                    ?: (null to emptyList())

                if (interestFrame != null) {
                    echoWarning("Interest detected!")
                    launch(Dispatchers.IO) {
                        interestDetections
                            .sortedBy { it.confidence }
                            .forEach { it.drawOn(interestFrame) }
                        ImageIO.write(interestFrame, "png", File(evidenceFolder, file.nameWithoutExtension + ".png"))
                    }
                } else {
                    echoInfo("Boring...")
                }
                launch(Dispatchers.IO) {
                    if (interestFrame != null)
                        file.copyTo(File(interestFolder, file.name), overwrite = true)
                    file.delete()
                }
            }

            echoInfo("Time usage: $time, ${"%.4f".format(video.size.toDouble() / time.inWholeSeconds)} fps")
            System.gc()
        }
        // clean up
        yoloV8.close()
        env.close()
    }
}
